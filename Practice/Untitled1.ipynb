{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cdcf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accacfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('1_boston_housing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8766b3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim       0\n",
       "zn         0\n",
       "indus      0\n",
       "chas       0\n",
       "nox        0\n",
       "rm         0\n",
       "age        0\n",
       "dis        0\n",
       "rad        0\n",
       "tax        0\n",
       "ptratio    0\n",
       "b          0\n",
       "lstat      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae55537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crim         3.613524\n",
       "zn          11.363636\n",
       "indus       11.136779\n",
       "chas         0.069170\n",
       "nox          0.554695\n",
       "rm           6.284634\n",
       "age         68.574901\n",
       "dis          3.795043\n",
       "rad          9.549407\n",
       "tax        408.237154\n",
       "ptratio     18.455534\n",
       "b          356.674032\n",
       "lstat       12.653063\n",
       "MEDV        22.532806\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49394e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b0d3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('MEDV',axis=1)\n",
    "y=df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eda4616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled x train (354, 13)\n",
      "Shape of scaled x test (152, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.3)\n",
    "scale=MinMaxScaler()\n",
    "x_train_scaled=scale.fit_transform(x_train)\n",
    "x_test_scaled=scale.fit_transform(x_test)\n",
    "print(\"Shape of scaled x train\",x_train_scaled.shape)\n",
    "print(\"Shape of scaled x test\",x_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ac79e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d17e285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01832216e-04, 9.47368421e-01, 9.57406709e-02, 0.00000000e+00,\n",
       "       1.85185185e-02, 7.45928339e-01, 3.00000000e-01, 4.73097047e-01,\n",
       "       8.69565217e-02, 1.08778626e-01, 3.51063830e-01, 9.73372333e-01,\n",
       "       3.80794702e-02])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ac1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def house_price_prediction():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(128,activation='relu', input_shape=(x_train_scaled[0].shape)))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "763367ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "354/354 [==============================] - 2s 2ms/step - loss: 193.8786 - mae: 10.1182 - val_loss: 90.1085 - val_mae: 6.1752\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.0014 - mae: 4.6146 - val_loss: 60.3108 - val_mae: 4.9564\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 30.3468 - mae: 3.9500 - val_loss: 70.5434 - val_mae: 5.6854\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 23.5943 - mae: 3.5009 - val_loss: 36.6220 - val_mae: 3.7503\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 20.4366 - mae: 3.2219 - val_loss: 45.1488 - val_mae: 4.3849\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 18.6020 - mae: 3.0642 - val_loss: 28.3945 - val_mae: 3.2591\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 17.7733 - mae: 3.0687 - val_loss: 51.8015 - val_mae: 4.9664\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 17.4197 - mae: 2.9248 - val_loss: 35.1387 - val_mae: 3.6911\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 16.1268 - mae: 2.8351 - val_loss: 34.1589 - val_mae: 3.5149\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 16.2447 - mae: 2.8016 - val_loss: 31.7546 - val_mae: 3.4369\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 15.8624 - mae: 2.8464 - val_loss: 39.0754 - val_mae: 4.0028\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 15.1194 - mae: 2.6914 - val_loss: 42.5528 - val_mae: 4.5161\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 14.2908 - mae: 2.6775 - val_loss: 41.9600 - val_mae: 4.4212\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 15.4195 - mae: 2.7377 - val_loss: 31.0454 - val_mae: 3.3671\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 12.9062 - mae: 2.6129 - val_loss: 31.1947 - val_mae: 3.5913\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 13.9399 - mae: 2.6699 - val_loss: 36.7698 - val_mae: 4.1282\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 12.7942 - mae: 2.5264 - val_loss: 25.8283 - val_mae: 3.0962\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 13.2566 - mae: 2.6829 - val_loss: 29.3885 - val_mae: 3.3452\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 11.6918 - mae: 2.4683 - val_loss: 28.2906 - val_mae: 3.2855\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 12.7878 - mae: 2.5578 - val_loss: 32.5721 - val_mae: 3.9194\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 11.4509 - mae: 2.5058 - val_loss: 24.3996 - val_mae: 3.0736\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 12.2487 - mae: 2.4531 - val_loss: 29.1543 - val_mae: 3.5236\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 12.6094 - mae: 2.5207 - val_loss: 31.1720 - val_mae: 3.7713\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 11.1968 - mae: 2.3005 - val_loss: 21.5384 - val_mae: 2.9043\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 10.2700 - mae: 2.2429 - val_loss: 29.7218 - val_mae: 3.8398\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 10.8177 - mae: 2.2972 - val_loss: 17.2633 - val_mae: 2.6738\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 11.6832 - mae: 2.4551 - val_loss: 23.2873 - val_mae: 3.1688\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 10.3738 - mae: 2.2795 - val_loss: 20.6389 - val_mae: 2.8367\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.5759 - mae: 2.2195 - val_loss: 33.4800 - val_mae: 4.2842\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.8617 - mae: 2.2679 - val_loss: 32.2945 - val_mae: 4.3619\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.7683 - mae: 2.3055 - val_loss: 25.7967 - val_mae: 3.4623\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.6553 - mae: 2.2535 - val_loss: 46.6628 - val_mae: 5.3007\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 10.0117 - mae: 2.3073 - val_loss: 29.8452 - val_mae: 3.7493\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.6544 - mae: 2.1676 - val_loss: 21.1429 - val_mae: 3.1185\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.3910 - mae: 2.1305 - val_loss: 21.6162 - val_mae: 3.2208\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.2573 - mae: 2.2448 - val_loss: 22.2337 - val_mae: 3.1986\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.2998 - mae: 2.0581 - val_loss: 21.6728 - val_mae: 3.3003\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.1919 - mae: 2.1585 - val_loss: 24.8653 - val_mae: 3.4313\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.4030 - mae: 2.1162 - val_loss: 24.0593 - val_mae: 3.3509\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 9.4833 - mae: 2.2784 - val_loss: 27.2695 - val_mae: 3.7308\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.5785 - mae: 2.1343 - val_loss: 33.7852 - val_mae: 4.3637\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.9863 - mae: 2.0919 - val_loss: 26.2429 - val_mae: 3.4474\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.4484 - mae: 2.1109 - val_loss: 18.4014 - val_mae: 2.8099\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.8939 - mae: 2.1730 - val_loss: 23.2409 - val_mae: 3.5164\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 8.3393 - mae: 2.1412 - val_loss: 26.0195 - val_mae: 3.8577\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 8.7316 - mae: 2.1044 - val_loss: 19.7033 - val_mae: 3.2671\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.7894 - mae: 2.1096 - val_loss: 25.6362 - val_mae: 3.5049\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.4916 - mae: 1.9982 - val_loss: 20.0094 - val_mae: 3.3182\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.7585 - mae: 2.0160 - val_loss: 18.1631 - val_mae: 2.8077\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 7.6321 - mae: 1.9902 - val_loss: 21.9563 - val_mae: 3.0614\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.9610 - mae: 2.0679 - val_loss: 21.0259 - val_mae: 3.4299\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 7.6989 - mae: 2.0076 - val_loss: 30.2485 - val_mae: 4.1021\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 8.0928 - mae: 2.0484 - val_loss: 26.1955 - val_mae: 3.5949\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 7.8156 - mae: 2.0214 - val_loss: 13.5970 - val_mae: 2.4305\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.8411 - mae: 2.0112 - val_loss: 19.2679 - val_mae: 2.9599\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.8465 - mae: 1.8876 - val_loss: 13.0941 - val_mae: 2.4360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 7.2713 - mae: 1.9853 - val_loss: 35.3041 - val_mae: 4.7052\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.6953 - mae: 2.0320 - val_loss: 33.7955 - val_mae: 4.7965\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.5353 - mae: 2.0588 - val_loss: 18.0221 - val_mae: 2.9327\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.8470 - mae: 2.0657 - val_loss: 19.3396 - val_mae: 3.0189\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.1778 - mae: 1.8272 - val_loss: 29.7151 - val_mae: 4.0897\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.5859 - mae: 2.0421 - val_loss: 18.3427 - val_mae: 2.9470\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.8040 - mae: 2.0292 - val_loss: 17.0919 - val_mae: 2.7114\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.8954 - mae: 1.8929 - val_loss: 20.3545 - val_mae: 3.3492\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.7187 - mae: 2.0340 - val_loss: 17.7134 - val_mae: 2.9431\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.3857 - mae: 1.8092 - val_loss: 31.7740 - val_mae: 4.4779\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.7482 - mae: 2.0431 - val_loss: 23.5798 - val_mae: 3.6836\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.4319 - mae: 1.8517 - val_loss: 23.2049 - val_mae: 3.5483\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 6.4417 - mae: 1.8780 - val_loss: 31.9619 - val_mae: 4.5636\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.8985 - mae: 1.9702 - val_loss: 20.9692 - val_mae: 3.4556\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 7.0396 - mae: 1.9796 - val_loss: 16.0538 - val_mae: 2.8716\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.7600 - mae: 1.9265 - val_loss: 25.2215 - val_mae: 3.7837\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.1077 - mae: 1.8195 - val_loss: 20.2901 - val_mae: 3.4116\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 5.8574 - mae: 1.8340 - val_loss: 31.2922 - val_mae: 4.6077\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.2725 - mae: 1.8163 - val_loss: 22.4820 - val_mae: 3.4891\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 5.7780 - mae: 1.7830 - val_loss: 16.4055 - val_mae: 2.8992\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 6.4007 - mae: 1.8780 - val_loss: 18.6871 - val_mae: 3.1522\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 5.1847 - mae: 1.7221 - val_loss: 24.0051 - val_mae: 3.7608\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 5.5357 - mae: 1.8310 - val_loss: 18.3492 - val_mae: 3.0640\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 5.1095 - mae: 1.7042 - val_loss: 27.3926 - val_mae: 4.1306\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 6.1006 - mae: 1.8259 - val_loss: 19.8263 - val_mae: 3.2644\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 5.1206 - mae: 1.6827 - val_loss: 21.9301 - val_mae: 3.8012\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 5.5619 - mae: 1.7554 - val_loss: 25.5545 - val_mae: 3.9571\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.8482 - mae: 1.6590 - val_loss: 16.0694 - val_mae: 2.8208\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 5.5002 - mae: 1.7849 - val_loss: 23.8642 - val_mae: 3.8607\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 5.9214 - mae: 1.8504 - val_loss: 32.9591 - val_mae: 4.8389\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 5.2398 - mae: 1.7100 - val_loss: 23.7013 - val_mae: 3.7444\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.7389 - mae: 1.6398 - val_loss: 20.7053 - val_mae: 3.3079\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 5.5803 - mae: 1.6746 - val_loss: 25.6159 - val_mae: 3.7551\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.8778 - mae: 1.6397 - val_loss: 21.4531 - val_mae: 3.4499\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.9744 - mae: 1.6395 - val_loss: 19.8703 - val_mae: 3.1644\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.3008 - mae: 1.5428 - val_loss: 18.9360 - val_mae: 3.3053\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.6258 - mae: 1.6142 - val_loss: 17.0369 - val_mae: 2.6876\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.8585 - mae: 1.6540 - val_loss: 18.7927 - val_mae: 3.0262\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.5093 - mae: 1.5991 - val_loss: 21.2561 - val_mae: 3.4004\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.6135 - mae: 1.6248 - val_loss: 22.2733 - val_mae: 3.2589\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 4.4147 - mae: 1.6225 - val_loss: 22.0298 - val_mae: 3.5611\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.4222 - mae: 1.6040 - val_loss: 28.0598 - val_mae: 4.5642\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.5700 - mae: 1.6119 - val_loss: 18.6547 - val_mae: 3.2250\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.0352 - mae: 1.5683 - val_loss: 28.6242 - val_mae: 4.2936\n"
     ]
    }
   ],
   "source": [
    "model=house_price_prediction()\n",
    "history=model.fit(x=x_train_scaled, y=y_train, batch_size=1, verbose=1, epochs=100, validation_data=(x_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ebf036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data 24.0\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted output [[40.873436]]\n"
     ]
    }
   ],
   "source": [
    "test_input=[[1.01832216e-04, 9.47368421e-01, 9.57406709e-02, 0.00000000e+00,\n",
    "       1.85185185e-02, 7.45928339e-01, 3.00000000e-01, 4.73097047e-01,\n",
    "       8.69565217e-02, 1.08778626e-01, 3.51063830e-01, 9.73372333e-01,\n",
    "       3.80794702e-02]]\n",
    "print('Actual data', 24.0)\n",
    "print('Predicted output', model.predict(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ea11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
